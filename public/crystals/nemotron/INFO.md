# Nemotron 3 Nano

**Year:** 2025
**Type:** Hybrid Latent MoE
**Parameters:** 30B (3B Active)
**Developer:** Nvidia
**Concept:** Agentic Foundation

## The Agentic Spark
Nemotron 3 Nano represents a shift from pure "chat" models to "action" models. Its **Hybrid Latent MoE** architecture allows it to maintain a massive reservoir of knowledge (30B parameters) while only activating a tiny, efficient slice (3B) for any given token generation.

### Architectural Highlights
- **Latent Routing:** Experts are selected in a latent space before full activation, saving compute.
- **Agentic Tuning:** Specifically fine-tuned for tool use, function calling, and multi-step reasoning.
- **Edge Compatible:** The 3B active footprint allows it to run on high-end edge devices (Orin, Apple Silicon) with extreme speed.

> "Intelligence is not just knowing, but reducing the cost of knowing."
